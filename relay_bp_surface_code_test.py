#!/usr/bin/env python3
"""
Test Relay-BP on realistic surface code syndromes from stim.

This script compares Relay-BP performance against PyMatching on surface codes,
using realistic syndromes generated by stim's circuit simulation.
"""

import stim
import pymatching
import numpy as np
from typing import Tuple, Dict, List
import time

# Import our implementations
from relay_bp import RelayBP
from surface_code_matrices import extract_matrices_from_dem


def create_surface_code_problem(distance: int, rounds: int, noise_level: float) -> Tuple[np.ndarray, np.ndarray, np.ndarray, stim.Circuit, stim.DetectorErrorModel, pymatching.Matching]:
    """
    Create a complete surface code problem for testing.
    
    Returns:
        (H, A, p, circuit, dem, pymatching_decoder)
    """
    # Create circuit
    circuit = stim.Circuit.generated(
        "surface_code:rotated_memory_x",
        rounds=rounds,
        distance=distance,
        after_clifford_depolarization=noise_level,
        after_reset_flip_probability=noise_level,
        before_measure_flip_probability=noise_level,
        before_round_data_depolarization=noise_level
    )
    
    # Extract detector error model
    dem = circuit.detector_error_model(decompose_errors=True)
    
    # Extract matrices for Relay-BP
    H, A, p = extract_matrices_from_dem(dem)
    
    # Create PyMatching decoder
    pymatching_decoder = pymatching.Matching.from_detector_error_model(dem)
    
    return H, A, p, circuit, dem, pymatching_decoder


def sample_realistic_syndromes(circuit: stim.Circuit, num_samples: int, seed: int = None) -> Tuple[np.ndarray, np.ndarray]:
    """
    Sample realistic syndromes using stim's circuit simulation.
    
    Returns:
        (syndromes, logical_observables) - both as binary arrays
    """
    if seed is not None:
        np.random.seed(seed)
    
    sampler = circuit.compile_detector_sampler()
    syndromes, logical_observables = sampler.sample(
        shots=num_samples,
        separate_observables=True
    )
    
    return syndromes, logical_observables


def test_single_syndrome(H: np.ndarray, A: np.ndarray, p: np.ndarray, 
                        syndrome: np.ndarray, true_logical: np.ndarray,
                        pymatching_decoder: pymatching.Matching,
                        relay_bp_params: Dict = None) -> Dict:
    """
    Test both decoders on a single syndrome.
    
    Returns:
        Dictionary with comparison results
    """
    if relay_bp_params is None:
        relay_bp_params = {
            'S': 3,
            'R': 50, 
            'T_r': 40,
            'gamma_range': (-0.3, 0.9)
        }
    
    results = {
        'syndrome_weight': np.sum(syndrome),
        'true_logical': true_logical.copy()
    }
    
    # Test PyMatching
    start_time = time.time()
    pymatching_prediction = pymatching_decoder.decode(syndrome)
    pymatching_time = time.time() - start_time
    
    pymatching_error = not np.array_equal(pymatching_prediction, true_logical)
    
    results['pymatching'] = {
        'prediction': pymatching_prediction.copy(),
        'logical_error': pymatching_error,
        'time': pymatching_time
    }
    
    # Test Relay-BP
    relay_decoder = RelayBP(H, A, p)
    
    start_time = time.time()
    relay_result = relay_decoder.decode(
        syndrome,
        S=relay_bp_params['S'],
        R=relay_bp_params['R'],
        T_r=relay_bp_params['T_r'],
        gamma_range=relay_bp_params['gamma_range']
    )
    relay_time = time.time() - start_time
    
    # Extract logical prediction from error estimate
    if relay_result.success:
        relay_logical_prediction = (A @ relay_result.error_estimate) % 2
    else:
        # If decoding failed, use all-zero prediction
        relay_logical_prediction = np.zeros(len(true_logical), dtype=np.int32)
    
    relay_error = not np.array_equal(relay_logical_prediction, true_logical)
    
    results['relay_bp'] = {
        'success': relay_result.success,
        'prediction': relay_logical_prediction.copy(),
        'logical_error': relay_error,
        'error_estimate': relay_result.error_estimate.copy(),
        'weight': relay_result.weight,
        'iterations': relay_result.iterations,
        'solutions_found': relay_result.solutions_found,
        'time': relay_time
    }
    
    return results


def batch_comparison_test(distance: int, rounds: int, noise_level: float, 
                         num_samples: int, seed: int = 42) -> Dict:
    """
    Run a batch comparison between Relay-BP and PyMatching.
    
    Returns:
        Dictionary with aggregated results
    """
    print(f"\nBatch Comparison Test")
    print(f"Distance: {distance}, Rounds: {rounds}, Noise: {noise_level}")
    print(f"Samples: {num_samples}")
    print("-" * 50)
    
    # Create problem
    print("1. Creating surface code problem...")
    H, A, p, circuit, dem, pymatching_decoder = create_surface_code_problem(
        distance, rounds, noise_level
    )
    
    print(f"   Problem size: {H.shape[0]} detectors, {H.shape[1]} error mechanisms")
    print(f"   Logical observables: {A.shape[0]}")
    
    # Sample syndromes
    print(f"2. Sampling {num_samples} realistic syndromes...")
    syndromes, true_logicals = sample_realistic_syndromes(circuit, num_samples, seed)
    
    syndrome_weights = np.sum(syndromes, axis=1)
    avg_syndrome_weight = np.mean(syndrome_weights)
    nonzero_syndromes = np.sum(syndrome_weights > 0)
    
    print(f"   Average syndrome weight: {avg_syndrome_weight:.2f}")
    print(f"   Non-zero syndromes: {nonzero_syndromes}/{num_samples}")
    
    # Run comparisons
    print(f"3. Running decoder comparisons...")
    
    pymatching_errors = 0
    relay_bp_errors = 0
    relay_bp_failures = 0
    
    pymatching_times = []
    relay_bp_times = []
    relay_bp_iterations = []
    
    # Test on subset for detailed analysis
    detailed_results = []
    
    for i in range(num_samples):
        if i % (num_samples // 10) == 0:  # Progress indicator
            print(f"   Progress: {i}/{num_samples}")
        
        syndrome = syndromes[i]
        true_logical = true_logicals[i]
        
        # Skip zero syndromes (trivial cases)
        if np.sum(syndrome) == 0:
            continue
        
        result = test_single_syndrome(
            H, A, p, syndrome, true_logical, pymatching_decoder,
            relay_bp_params={'S': 2, 'R': 30, 'T_r': 25, 'gamma_range': (-0.25, 0.85)}
        )
        
        # Aggregate statistics
        if result['pymatching']['logical_error']:
            pymatching_errors += 1
        
        if result['relay_bp']['logical_error']:
            relay_bp_errors += 1
        
        if not result['relay_bp']['success']:
            relay_bp_failures += 1
        
        pymatching_times.append(result['pymatching']['time'])
        relay_bp_times.append(result['relay_bp']['time'])
        relay_bp_iterations.append(result['relay_bp']['iterations'])
        
        # Store first few results for detailed analysis
        if len(detailed_results) < 5:
            detailed_results.append(result)
    
    # Calculate rates
    effective_samples = nonzero_syndromes  # Only count non-zero syndromes
    
    pymatching_error_rate = pymatching_errors / effective_samples if effective_samples > 0 else 0
    relay_bp_error_rate = relay_bp_errors / effective_samples if effective_samples > 0 else 0
    relay_bp_failure_rate = relay_bp_failures / effective_samples if effective_samples > 0 else 0
    
    # Results summary
    results = {
        'problem': {
            'distance': distance,
            'rounds': rounds, 
            'noise_level': noise_level,
            'num_detectors': H.shape[0],
            'num_errors': H.shape[1],
            'num_observables': A.shape[0]
        },
        'samples': {
            'total': num_samples,
            'effective': effective_samples,
            'avg_syndrome_weight': avg_syndrome_weight
        },
        'pymatching': {
            'logical_errors': pymatching_errors,
            'error_rate': pymatching_error_rate,
            'avg_time': np.mean(pymatching_times),
            'total_time': np.sum(pymatching_times)
        },
        'relay_bp': {
            'logical_errors': relay_bp_errors,
            'error_rate': relay_bp_error_rate,
            'failures': relay_bp_failures,
            'failure_rate': relay_bp_failure_rate,
            'success_rate': 1 - relay_bp_failure_rate,
            'avg_time': np.mean(relay_bp_times),
            'total_time': np.sum(relay_bp_times),
            'avg_iterations': np.mean(relay_bp_iterations)
        },
        'detailed_examples': detailed_results
    }
    
    return results


def print_comparison_results(results: Dict):
    """Print formatted comparison results."""
    prob = results['problem']
    samples = results['samples']
    pm = results['pymatching']
    rbp = results['relay_bp']
    
    print(f"\n{'='*60}")
    print(f"DECODER COMPARISON RESULTS")
    print(f"{'='*60}")
    
    print(f"\nProblem:")
    print(f"  Distance {prob['distance']}, {prob['rounds']} rounds, {prob['noise_level']} noise")
    print(f"  {prob['num_detectors']} detectors, {prob['num_errors']} error mechanisms")
    print(f"  {samples['effective']}/{samples['total']} non-trivial syndromes")
    print(f"  Average syndrome weight: {samples['avg_syndrome_weight']:.2f}")
    
    print(f"\nPerformance Comparison:")
    print(f"{'Metric':<25} {'PyMatching':<15} {'Relay-BP':<15} {'Advantage':<15}")
    print("-" * 70)
    
    print(f"{'Logical Error Rate':<25} {pm['error_rate']:<15.6f} {rbp['error_rate']:<15.6f} ", end="")
    if rbp['error_rate'] < pm['error_rate']:
        advantage = f"{pm['error_rate']/rbp['error_rate']:.2f}x better" if rbp['error_rate'] > 0 else "Perfect"
    else:
        advantage = f"{rbp['error_rate']/pm['error_rate']:.2f}x worse" if pm['error_rate'] > 0 else "Same"
    print(f"{advantage:<15}")
    
    print(f"{'Success Rate':<25} {'100.0%':<15} {rbp['success_rate']*100:<14.1f}% {'N/A':<15}")
    
    print(f"{'Avg Time (ms)':<25} {pm['avg_time']*1000:<15.2f} {rbp['avg_time']*1000:<15.2f} ", end="")
    speed_ratio = pm['avg_time'] / rbp['avg_time']
    if speed_ratio > 1:
        print(f"{speed_ratio:.2f}x faster")
    else:
        print(f"{1/speed_ratio:.2f}x slower")
    
    print(f"{'Avg Iterations':<25} {'N/A':<15} {rbp['avg_iterations']:<15.1f} {'N/A':<15}")
    
    print(f"\nDetailed Examples:")
    for i, example in enumerate(results['detailed_examples']):
        print(f"\nExample {i+1}:")
        print(f"  Syndrome weight: {example['syndrome_weight']}")
        print(f"  True logical: {example['true_logical']}")
        print(f"  PyMatching: {example['pymatching']['prediction']} (error: {example['pymatching']['logical_error']})")
        rbp = example['relay_bp']
        print(f"  Relay-BP: {rbp['prediction']} (error: {rbp['logical_error']}, success: {rbp['success']})")
        print(f"  Iterations: {rbp['iterations']}, Solutions: {rbp['solutions_found']}")


def main():
    """Run comprehensive Relay-BP vs PyMatching comparison."""
    print("Relay-BP Surface Code Testing")
    print("=" * 60)
    
    # Test parameters
    test_configs = [
        {'distance': 3, 'rounds': 3, 'noise': 0.001, 'samples': 1000},
        {'distance': 3, 'rounds': 3, 'noise': 0.002, 'samples': 500},
    ]
    
    all_results = []
    
    for config in test_configs:
        print(f"\n{'='*60}")
        print(f"TEST: Distance {config['distance']}, Noise {config['noise']}")
        print(f"{'='*60}")
        
        results = batch_comparison_test(
            distance=config['distance'],
            rounds=config['rounds'], 
            noise_level=config['noise'],
            num_samples=config['samples'],
            seed=42
        )
        
        print_comparison_results(results)
        all_results.append(results)
    
    # Overall summary
    print(f"\n{'='*60}")
    print(f"OVERALL SUMMARY")
    print(f"{'='*60}")
    
    for i, (config, results) in enumerate(zip(test_configs, all_results)):
        print(f"\nTest {i+1} (d={config['distance']}, p={config['noise']}):")
        pm_rate = results['pymatching']['error_rate']
        rbp_rate = results['relay_bp']['error_rate']
        rbp_success = results['relay_bp']['success_rate']
        
        print(f"  PyMatching error rate: {pm_rate:.6f}")
        print(f"  Relay-BP error rate: {rbp_rate:.6f} (success: {rbp_success:.1%})")
        
        if rbp_rate < pm_rate and rbp_rate > 0:
            print(f"  → Relay-BP {pm_rate/rbp_rate:.1f}x better logical error rate")
        elif rbp_rate > pm_rate:
            print(f"  → PyMatching {rbp_rate/pm_rate:.1f}x better logical error rate")
        else:
            print(f"  → Similar performance")
    
    print(f"\n✓ Relay-BP surface code testing completed!")
    return all_results


if __name__ == "__main__":
    try:
        results = main()
    except Exception as e:
        print(f"\nError during testing: {e}")
        raise
